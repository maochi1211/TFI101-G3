{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64bc72ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-14T03:40:16.942930Z",
     "start_time": "2022-01-14T03:40:16.929259Z"
    }
   },
   "outputs": [],
   "source": [
    "!apt-get -y install openjdk-8-jre-headless\n",
    "!pip install pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext\n",
    "spark = SparkSession.builder.master(\"local\").getOrCreate()\n",
    "sc = SparkContext.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b97ca5cb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-14T03:41:07.192155Z",
     "start_time": "2022-01-14T03:41:07.172255Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import DoubleType\n",
    "from pyspark.ml.feature import VectorAssembler,VectorIndexer, OneHotEncoder, StringIndexer\n",
    "from pyspark.ml.feature import Tokenizer, RegexTokenizer, StopWordsRemover, CountVectorizer, HashingTF, IDF\n",
    "from pyspark.ml.linalg import Vector\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.sql.functions import lower, length, size\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e02a5340",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-14T03:41:12.047333Z",
     "start_time": "2022-01-14T03:41:12.028531Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(<built-in function array>, dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5231b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b60022",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlp for multi-label classification\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_multilabel_classification\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd1abfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = spark.read.csv(\"/content/drive/MyDrive/Colab Notebooks/oriDataTag.csv\",\n",
    "                      inferSchema=True,\n",
    "                      header=True,\n",
    "                      encoding='utf-8')\n",
    "\n",
    "# get the dataset\n",
    "def get_dataset(data):\n",
    "\t\n",
    "    # Preprocessing and feature engineering\n",
    "    feature_prep_ori = data.select('sex', 'job', 'age', 'market', 'risk', 'joinTime', 'content', 'tag').orderBy('tag')\n",
    "    feature_prep = feature_prep_ori.dropna(how='any', thresh=None, subset=None)\n",
    "    feature_prep = StringIndexer(inputCol=\"sex\", outputCol=\"SexIndex\").fit(feature_prep).transform(feature_prep)\n",
    "    feature_prep = StringIndexer(inputCol=\"job\",outputCol=\"jobIndex\").fit(feature_prep).transform(feature_prep)\n",
    "    feature_prep = StringIndexer(inputCol=\"joinTime\",outputCol=\"joinTimeIndex\").fit(feature_prep).transform(feature_prep)\n",
    "    feature_prep = StringIndexer(inputCol=\"risk\",outputCol=\"riskIndex\").fit(feature_prep).transform(feature_prep)\n",
    "\n",
    "    data = feature_prep.toPandas()\n",
    "    data.to_csv('/content/drive/MyDrive/Colab Notebooks/dataTrain.csv', sep=',', encoding='utf_8_sig', index=True)\n",
    "    dataTrain=data.sample(frac=0.9)\n",
    "    dataTest=data[~data.index.isin(dataTrain.index)]\n",
    "    dataframe = dataTrain[['SexIndex', 'jobIndex', 'age', 'riskIndex', 'joinTimeIndex', 'tag']]\n",
    "\n",
    "\n",
    "    # 建立label的numpy array\n",
    "    featuresArray = []\n",
    "    labelArray = []\n",
    "    df = dataframe['tag']\n",
    "\n",
    "\n",
    "    for i in df:\n",
    "        index = (df.index)[0]\n",
    "        featuresVec = [0] * 5\n",
    "        featuresVec[0] = dataframe.loc[index, 'SexIndex']\n",
    "        featuresVec[1] = dataframe.loc[index, 'jobIndex']\n",
    "        featuresVec[2] = dataframe.loc[index, 'age']\n",
    "        featuresVec[3] = dataframe.loc[index, 'riskIndex']\n",
    "        featuresVec[4] = dataframe.loc[index, 'joinTimeIndex']\n",
    "        featuresArray.append(np.array(featuresVec))\n",
    "\n",
    "    tagVec = [0] * 13\n",
    "    for j in i.split(','):\n",
    "\n",
    "        try:\n",
    "            j = int(j)\n",
    "            if j < 14:\n",
    "                tagVec[j-1] = 1\n",
    "                  #data.loc[index, 'tag'] = str(tagVec)\n",
    "            else:\n",
    "                tagVec[j-1] = 1\n",
    "                  #data.loc[index, 'tag'] = str(tagVec)\n",
    "        \n",
    "        # print(np.array(tagVec))\n",
    "        except:\n",
    "            pass\n",
    "        labelArray.append(np.array(tagVec))\n",
    "    \n",
    "        index += 1\n",
    "\n",
    "    featuresArray = np.array(featuresArray)\n",
    "    labelArray = np.array(labelArray)\n",
    "\n",
    "    # summarize dataset shape\n",
    "    print(featuresArray.shape, labelArray.shape)\n",
    "    # summarize first few examples\n",
    "    for i in range(10):\n",
    "        print(featuresArray[i], labelArray[i])\n",
    "\n",
    "    return featuresArray, labelArray, dataTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91b0b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the model\n",
    "def get_model(n_inputs, n_outputs):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, input_dim=n_inputs, activation='relu'))# kernel_initializer='he_uniform', \n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(128, activation='relu'))# kernel_initializer='he_uniform',\n",
    "    # model.add(Dropout(0.1))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    # model.add(Dropout(0.5))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    # model.add(Dropout(0.2))\n",
    "    model.add(Dense(n_outputs, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b35d9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate a model using repeated k-fold cross-validation\n",
    "from sklearn.utils import class_weight\n",
    "def evaluate_model(X, y):\n",
    "\n",
    "\tresults = list()\n",
    "\t\n",
    "\ttime=0\n",
    "\tn_inputs, n_outputs = X.shape[1], y.shape[1]\n",
    "\tprint(X.shape[1], y.shape[1])\n",
    "\n",
    "\t# define evaluation procedure\n",
    "\t# cv = RepeatedKFold(n_splits=10, n_repeats=1, random_state=1)\n",
    "\tX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\t\n",
    "\n",
    "\t# for i in range(epoch):\n",
    "\t# \tmodel = get_model(n_inputs, n_outputs)\n",
    "\t# \tmodel.fit(X_train, y_train, verbose=2, epochs=100)\n",
    "\t# \tyhat = model.predict(X_test)\n",
    "\t# \tyhat = yhat.round()\n",
    "\t# \tacc = accuracy_score(y_test, yhat)\n",
    "\t# \tprint('>%.3f' % acc)\n",
    "\t# \tresults.append(acc)\n",
    "\t\n",
    "\t# enumerate folds\n",
    "\t# y_pre = np.zeros((179, 13))\n",
    "\tmodel = get_model(n_inputs, n_outputs)\n",
    "\n",
    "\tclass_weight = {0:1.87, 1:4.51, 2:0.4, 3:1.8, 4:1.81, 5:0.5, 6:5,\n",
    "\t         7:2.99, 8:1.81, 9:8, 10:8, 11:4.2, 12:2.28}\n",
    "\tmodel.fit(X_train, y_train, verbose=0, epochs=1000)\n",
    " \n",
    "\tyhat = model.predict(X_test)\n",
    "\t# for train_ix, test_ix in cv.split(X):\n",
    "\t# \t# prepare data\n",
    "\t# \tX_train, X_test = X[train_ix], X[test_ix]\n",
    "\t# \ty_train, y_test = y[train_ix], y[test_ix]\n",
    "\t# \t# define model\n",
    "\t# \tmodel = get_model(n_inputs, n_outputs)\n",
    "\t# \t# fit model\n",
    "\t# \tmodel.fit(X_train, y_train, verbose=0, epochs=10)\n",
    "\t# \t# make a prediction on the test set\n",
    "\t# \tyhat = model.predict(X_test)\n",
    "\t\t\n",
    "\t\t# round probabilities to class labels\n",
    "\t\t# for yn in range(len(yhat)):\n",
    "\t\t# \tindex=0\n",
    "\t\t# \t# for iyn in yhat[yn]:\n",
    "\t\t\t\t\n",
    "\t\t# \t\t# print(iyn)\n",
    "\t\t# \tprint(yhat[yn].round(4))\n",
    "\t\t\t\t# index += 1\n",
    "\t\t# print('#####################################################################################')\n",
    "\t\t# yhat = yhat.round()\n",
    "\t\t# # print(yhat.round(4))\n",
    "\t\t# # calculate accuracy\n",
    "\t\t# acc = accuracy_score(y_test, yhat)\n",
    "\t\t# # store result\n",
    "\t\t# print('>%.3f' % acc)\n",
    "\t\t# results.append(acc)\n",
    "\t\t# #y_pre.append(yhat)\n",
    "\t\t# y_pre+=yhat\n",
    "\t\t# time+=1\n",
    "\t#y_pre=y_pre/time\n",
    "\t# for i in range(len(yhat)):\n",
    "\t# \tprint(yhat[i])\n",
    "\n",
    "\t\n",
    "\t\t# print(yhat[i].round(4))\n",
    "\tmodel.save(\"/content/drive/MyDrive/Colab Notebooks/modelTag.h5\")\n",
    "\treturn results\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d28afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "X, y, dataset = get_dataset(data)\n",
    "# evaluate model\n",
    "results = evaluate_model(X, y)\n",
    "# summarize performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(results), std(results)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438b3309",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import random\n",
    "pd.options.display.max_columns = None\n",
    "test = list()\n",
    "\n",
    "\n",
    "X, y, dataset = get_dataset(data)\n",
    "dataset.reset_index(inplace=True, drop=False)\n",
    "for t in range(20):\n",
    "    x = random.randrange(0, 178)\n",
    "    test.append(x)\n",
    "\n",
    "\n",
    "dataframe = dataset[['SexIndex', 'jobIndex', 'age', 'riskIndex', 'joinTimeIndex', 'tag']]\n",
    "\n",
    "model = load_model('/content/drive/MyDrive/Colab Notebooks/modelTag.h5',compile=False)\n",
    "for i in test:\n",
    "    print(i)\n",
    "\n",
    "\n",
    "    # index = (dataset['index'].index)[0]\n",
    "    featuresVec = [0] * 5\n",
    "    featuresVec[0] = dataset.loc[i, 'SexIndex']\n",
    "    featuresVec[1] = dataset.loc[i, 'jobIndex']\n",
    "    featuresVec[2] = dataset.loc[i, 'age']\n",
    "    featuresVec[3] = dataset.loc[i, 'riskIndex']\n",
    "    featuresVec[4] = dataset.loc[i, 'joinTimeIndex']\n",
    "\n",
    "    input = np.array(featuresVec).reshape((1,5))\n",
    "    y_predicted = model.predict(input)\n",
    "    print(y_predicted.round(4))\n",
    "    print(dataset[i:i+1])\n",
    "    print('####################################################################')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
